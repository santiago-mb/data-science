{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "import operator\n",
    "import string\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "stop = stopwords.words('english') + list(string.punctuation) + list(string.digits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asociación de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levantar el corpus AP, separando cada noticia como un elemento distinto en un diccionario (``<DOCNO>``: ``<TEXT>``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apCorpus = {}\n",
    "with open('ap/ap.txt', 'r') as ap:\n",
    "    nextDoc = ap.readline()\n",
    "    while nextDoc:\n",
    "        docNumber = ap.readline().split(' ')[1]\n",
    "        ap.readline()\n",
    "        text = ap.readline().strip()\n",
    "        ap.readline()\n",
    "        ap.readline()\n",
    "        apCorpus[docNumber] = text\n",
    "        nextDoc = ap.readline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular el tamaño del vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apWords = set()\n",
    "apWordsFrequencies = {}\n",
    "apCorpusSize = 0\n",
    "for _, text in apCorpus.iteritems():\n",
    "    sentences = sent_detector.tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        tokenList = [i for i in nltk.word_tokenize(sentence.lower()) if i not in stop]\n",
    "        apCorpusSize += len(tokenList)\n",
    "        tokens = set(tokenList)\n",
    "        apWords |= tokens\n",
    "        for word in tokens:\n",
    "            if not word in apWordsFrequencies:\n",
    "                apWordsFrequencies[word] = 0\n",
    "            apWordsFrequencies[word] += sentence.count(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 42627\n",
      "Tamaño del corpus: 580913\n"
     ]
    }
   ],
   "source": [
    "print 'Tamaño del vocabulario:', len(apWords)\n",
    "print 'Tamaño del corpus:', apCorpusSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para las 500 palabras con más apariciones, calcular el par más asociado según la medida presentada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['said', '``', \"''\", \"'s\", 'would', 'percent', 'year', 'one', \"n't\", 'people', 'million', 'also', 'two', 'government', 'last', 'years', 'could', 'new', 'first', 'time', 'officials', 'state', 'billion', 'today', 'police', 'president', 'told', 'three', 'day', 'since', 'week', 'company', 'made', 'say', 'market', 'report', 'country', 'military', 'group', 'federal', 'many', 'members', 'reported', 'get', 'political', 'including', 'make', 'former', 'news', 'going', '10', 'work', 'home', 'spokesman', 'think', 'like', 'says', 'back', 'official', 'next', 'month', 'way', 'go', 'take', 'court', 'still', 'prices', \"'re\", 'called', 'four', 'found', 'part', 'much', 'nation', 'campaign', 'money', 'use', 'may', 'law', '...', 'program', 'case', 'plan', 'used', 'days', 'office', 'city', 'months', 'meeting', 'support', 'end', 'five', 'late', 'economic', 'help', 'several', 'trade', 'ago', 'public', 'men', 'later', 'world', 'man', 'expected', 'killed', 'least', 'began', 'workers', 'early', 'us', 'party', 'major', 'administration', 'saying', 'business', 'night', 'came', 'another', 'oil', 'system', 'agreement', 'dollar', 'chief', 'even', 'want', 'miles', 'family', 'among', 'took', 'children', 'asked', 'good', 'according', 'bill', '20', 'national', '30', 'number', 'aid', 'whether', 'statement', 'leader', 'drug', 'foreign', 'without', 'held', '1987', 'earlier', 'talks', 'war', 'know', 'left', 'higher', 'defense', 'see', 'must', 'death', 'announced', 'vote', 'set', 'decision', 'put', 'sales', 'past', 'high', 'leaders', 'interest', 'long', 'director', 'price', 'might', 'six', 'rose', 'charges', 'agency', 'area', 'pay', '15', 'trial', 'issue', 'rights', 'fire', 'power', 'died', 'control', 'economy', 'around', 'prison', 'second', 'come', 'de', 'countries', 'show', 'tax', 'life', 'air', '1986', 'well', 'rate', 'never', 'got', 'stock', 'cents', 'close', 'school', 'give', 'troops', 'force', \"'ve\", '1988', 'women', 'authorities', 'less', 'chairman', 'students', 'increase', 'rates', 'trading', 'problems', 'recent', 'general', 'security', 'lower', 'right', 'released', 'budget', 'near', 'board', 'forces', 'issues', '1989', 'hours', 'taken', \"'m\", 'away', 'reporters', 'went', 'share', 'cent', 'industry', 'policy', 'fell', 'attorney', 'black', 'conference', 'record', 'vice', 'condition', 'presidential', 'far', 'service', 'order', '12', 'top', 'received', 'head', 'whose', 'added', 'weeks', 'agreed', 'union', 'offer', 'capital', 'wife', 'bank', 'little', 'per', 'committee', 'information', 'employees', 'food', 'largest', 'others', 'states', 'place', 'member', 'known', 'television', 'cut', 'move', 'change', 'attack', 'cost', 'reports', 'opposition', 'election', 'companies', 'job', 'already', 'given', 'outside', 'points', 'private', '100', 'need', 'newspaper', 'average', 'across', 'groups', 'water', 'enough', 'lost', 'believe', 'scheduled', 'investigation', 'return', 'accused', 'nearly', 'plans', 'total', 'judge', 'sent', 'trying', '25', 'building', 'led', 'included', 'arrested', 'action', 'along', 'small', 'shot', 'continue', 'international', 'gave', 'peace', 'include', 'possible', 'human', 'contract', 'interview', 'local', 'half', 'keep', 'index', 'executive', 'become', '11', 'refused', 'financial', 'deal', 'call', 'eight', 'health', 'plant', 'times', 'met', 'point', 'morning', 'working', 'seven', 'town', 'every', '50', 'yen', 'strong', 'open', 'soldiers', 'filed', 'best', 'face', 'charged', 'making', 'army', 'closed', 'problem', 'hospital', 'real', 'important', 'study', 'special', 'elections', 'future', 'ca', 'son', 'leave', 'likely', 'planned', \"'ll\", 'production', 'something', 'lot', 'proposal', 'proposed', 'minister', 'spending', 'house', 'free', 'allow', 'taking', 'final', 'wanted', '40', 'central', 'toward', '1985', 'bid', 'allowed', 'involved', 'side', 'plane', 'better', 'find', 'sold', 'car', 'name', 'release', 'thousands', 'done', 'legislation', 'became', 'session', 'officers', 'jobs', 'failed', 'seen', 'shares', 'ordered', 'department', 'meet', 'strike', 'large', 'based', 'community', 'things', 'woman', 'officer', 'deficit', '13', 'continued', 'white', 'approved', 'run', 'radio', 'provide', 'third', 'violence', 'effort', 'big', 'senior', 'situation', 'level', 'paid', 'fall', 'areas', 'comment', 'victims', 'computer', 'center', 'previous', 'quoted', 'cases', 'sources', 'annual', 'hit', 'following', 'cause', 'summit', 'governor', 'behind', 'brought', 'main', 'calls', 'value', 'look', 'estimated', '18', 'able', 'position', 'within', 'convicted', 'recently', 'negotiations', '16', 'running', 'telephone', 'reached', 'appeared', 'evidence', 'income', 'worked', 'speech', 'futures', 'lead', 'period', 'ever', 'current', 'rebels', 'hope', 'products', 'declined', 'issued', 'really', 'great', 'probably', 'full', 'compared', 'north', 'programs', 'hearing']\n"
     ]
    }
   ],
   "source": [
    "apTop500Freq = []\n",
    "for i, (word, count) in enumerate(sorted(apWordsFrequencies.iteritems(), key=operator.itemgetter(1), reverse = True)):\n",
    "    if i >= 500:\n",
    "        break\n",
    "    apTop500Freq.append(word)\n",
    "print apTop500Freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 5\n",
    "def f2(x,y):\n",
    "    res = 0\n",
    "    for _, text in apCorpus.iteritems():\n",
    "        words = [i for i in nltk.word_tokenize(text.lower()) if i not in stop]\n",
    "        for i,word in enumerate(words):\n",
    "            if word == x:\n",
    "                for j in range(1, window + 1):\n",
    "                    if (i + j < len(words)):\n",
    "                        if words[i+j] == y:\n",
    "                            res += 1\n",
    "    return float(res)\n",
    "\n",
    "def f1(x):\n",
    "    return float(apWordsFrequencies[x])\n",
    "    \n",
    "def I(x, y):\n",
    "    p_x_y = f2(x,y) / apCorpusSize\n",
    "    p_x = f1(x) / apCorpusSize\n",
    "    p_y = f1(y) / apCorpusSize\n",
    "    return math.log((p_x_y / (p_x * p_y)), 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c94e7755f96b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mnew_I\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapTop500Freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapTop500Freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_pair_value\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnew_I\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mmax_pair_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_I\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-9f50f3bcfc72>\u001b[0m in \u001b[0;36mI\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mp_x_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mapCorpusSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mp_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mapCorpusSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mapCorpusSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-9f50f3bcfc72>\u001b[0m in \u001b[0;36mf2\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mapCorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_pair_value = 0\n",
    "max_pair = None\n",
    "for i in range(500):\n",
    "    print i\n",
    "    for j in range(i, 500):\n",
    "        new_I = I(apTop500Freq[i], apTop500Freq[j])\n",
    "        if max_pair_value < new_I:\n",
    "            max_pair_value = new_I\n",
    "            max_pair = (apTop500Freq[i], apTop500Freq[j])\n",
    "print max_pair, max_pair_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
